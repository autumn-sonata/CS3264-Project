{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "import numpy as np\n",
    "\n",
    "X = pd.read_csv(\"datasets/feature_updated_dataset_X.csv\")\n",
    "y = pd.read_csv(\"datasets/feature_updated_dataset_y.csv\")\n",
    "\n",
    "#rus = RandomOverSampler(random_state=69)\n",
    "#X_rus, y_rus = rus.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "y_train, y_test = y_train.values.ravel(), y_test.values.ravel()\n",
    "# print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_feature1_train = X_train[['http', 'https', 'www', 'url_length', 'url_entropy',  'domain_extension']]\n",
    "# X_feature1_test = X_test[['http', 'https', 'www', 'url_length', 'url_entropy', 'domain_extension']]\n",
    "\n",
    "# X_feature2_train = X_train[['digit_count', 'percentage_count', 'dot_count', 'bs_count', 'dash_count', 'params_count', 'subdomains_count']]\n",
    "# X_feature2_test = X_test[['digit_count', 'percentage_count', 'dot_count', 'bs_count', 'dash_count', 'params_count', 'subdomains_count']]\n",
    "\n",
    "# X_features_boot_train = X_train[['http', 'https', 'www', 'url_length', 'url_entropy',  'domain_extension', 'digit_count', 'percentage_count', 'dot_count', 'dash_count', 'subdomains_count']]\n",
    "# X_features_boot_test = X_test[['http', 'https', 'www', 'url_length', 'url_entropy',  'domain_extension', 'digit_count', 'percentage_count', 'dot_count', 'dash_count', 'subdomains_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9622386535523153 | F1 score: 0.9614002792741423 | ['http' 'https' 'www' 'url_length' 'digit_count' 'percentage_count'\n",
      " 'dot_count' 'bs_count' 'dash_count' 'url_entropy' 'params_count'\n",
      " 'subdomains_count' 'domain_extension'] | criterion: gini\n"
     ]
    }
   ],
   "source": [
    "# Modelling\n",
    "# 1) Logistic Regression\n",
    "model_lr1 = LogisticRegression(max_iter=500)\n",
    "# 2) SVM\n",
    "#model_svm = svm.SVC()\n",
    "# 3) Random Forest Classifier\n",
    "model_rfc1 = RandomForestClassifier(verbose=0, n_estimators=50, max_depth=20, min_samples_leaf=2, min_samples_split=2, random_state=69)\n",
    "model_rfc2 = RandomForestClassifier(verbose=0, n_estimators=50, max_depth=20, min_samples_leaf=2, min_samples_split=2, random_state=69)\n",
    "model_rfc3 = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=69)\n",
    "# data = [(model_rfc1, X_train, X_test)]\n",
    "data = [(model_rfc3, X_train, X_test)]\n",
    "\n",
    "#data = [(model_rfc1, X_features_boot_train, X_features_boot_test)]\n",
    "#data = [(model_rfc1, X_train, X_test), (model_rfc2, X_train, X_test), (model_rfc3, X_train, X_test)]\n",
    "#data = [(model_rfc1, X_train, X_test), (model_rfc2, X_features_boot_train, X_features_boot_test)]\n",
    "\n",
    "for data_set in data:\n",
    "    model, X_train, X_test = data_set\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Verifying model fit\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"Accuracy: {accuracy} | F1 score: {f1} | {X_train.columns.values} | criterion: {model.criterion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0 : 0.875\n",
      "FNR for class 0 : 0.0\n",
      "Accuracy for class 1 : 0.875\n",
      "FNR for class 1 : 1.0\n",
      "Accuracy for class 2 : 0.75\n",
      "FNR for class 2 : 0.3333333333333333\n",
      "Accuracy for class 3 : 1.0\n",
      "FNR for class 3 : 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def calc_FNR_accuracy(y_true, y_pred):\n",
    "  conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "  for label_class in range(4):\n",
    "    \n",
    "    FN = sum(conf_matrix[label_class][i] for i in range(len(conf_matrix)) if i != label_class)  \n",
    "    \n",
    "    TP = conf_matrix[label_class][label_class]  \n",
    "    \n",
    "    TN = np.sum(np.delete(np.delete(conf_matrix, label_class, axis=0), label_class, axis=1))\n",
    "    \n",
    "    accuracy = (TP + TN) / np.sum(conf_matrix)\n",
    "    print(\"Accuracy for class\", label_class, \":\", accuracy)\n",
    "\n",
    "    FNR = FN / (FN + TP) if (FN + TP) > 0 else -1\n",
    "    print(\"FNR for class\", label_class, \":\", FNR)\n",
    "\n",
    "calc_FNR_accuracy([2, 0, 2, 2, 0, 1, 3, 3], [0, 0, 2, 2, 0, 2, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_rfc1.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Export the model to a file\n",
    "joblib.dump(model_rfc1, 'model_rfc1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http : 0.044096\n",
      "https : 0.164525\n",
      "www : 0.175034\n",
      "url_length : 0.228288\n",
      "digit_count : 0.232818\n",
      "percentage_count : 0.263447\n",
      "dot_count : 0.267785\n",
      "bs_count : 0.273873\n",
      "dash_count : 0.469303\n",
      "url_entropy : 0.478574\n",
      "params_count : 0.526618\n",
      "subdomains_count : 0.887349\n",
      "domain_extension : 1.000000\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for data_set in data:\n",
    "  model, X_train, X_test = data_set\n",
    "  rf_model = model\n",
    "  importances = rf_model.feature_importances_\n",
    "  scaled_importances = importances / np.max(importances)\n",
    "  values = X_train.columns\n",
    "  scaled_importances.sort()\n",
    "\n",
    "  for i in range(len(importances)):\n",
    "    print(values[i], \":\" ,f\"{scaled_importances[i]:.6f}\")\n",
    "  print(\"=====================================\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[0;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_rfc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m importances \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mimportances_mean\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature, importance \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns, importances):\n",
      "File \u001b[0;32m~/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/inspection/_permutation_importance.py:290\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[1;32m    287\u001b[0m     scorers_dict \u001b[38;5;241m=\u001b[39m _check_multimetric_scoring(estimator, scoring)\n\u001b[1;32m    288\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m _MultimetricScorer(scorers\u001b[38;5;241m=\u001b[39mscorers_dict)\n\u001b[0;32m--> 290\u001b[0m baseline_score \u001b[38;5;241m=\u001b[39m \u001b[43m_weights_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m scores \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(\n\u001b[1;32m    293\u001b[0m     delayed(_calculate_permutation_scores)(\n\u001b[1;32m    294\u001b[0m         estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    305\u001b[0m )\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(baseline_score, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/inspection/_permutation_importance.py:26\u001b[0m, in \u001b[0;36m_weights_scorer\u001b[0;34m(scorer, estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scorer(estimator, X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:415\u001b[0m, in \u001b[0;36m_PassthroughScorer.__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    414\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Method that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/base.py:764\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:905\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    885\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:945\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    924\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m    Predict class probabilities for X.\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m        classes corresponds to that in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m    947\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/utils/validation.py:1622\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(model_rfc1, X, y, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "\n",
    "for feature, importance in zip(X.columns, importances):\n",
    "    print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http: 1.0\n",
      "https: 0.18423200705173653\n",
      "www: 0.7532694408682497\n",
      "url_length: 0.2621509177106623\n",
      "digit_count: 0.20198611303530561\n",
      "percentage_count: 0.4408051768822412\n",
      "dot_count: 0.23032560666569807\n",
      "bs_count: 0.04422447770349619\n",
      "dash_count: 0.22617372240744488\n",
      "url_entropy: 0.13130205850696972\n",
      "params_count: 0.6064734314995082\n"
     ]
    }
   ],
   "source": [
    "scaled_importances = importances / np.max(importances)\n",
    "for feature, importance in zip(X.columns, scaled_importances):\n",
    "    print(f\"{feature}: {importance}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "for i in range(3):\n",
    "    tree = model_rfc1.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X_train.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "phish_urls = pd.read_csv(\"datasets/phishtank_phish_urls.csv\")\n",
    "malicious_urls = pd.read_csv(\"datasets/malicious_phish.csv\")['url']\n",
    "\n",
    "phish_urls_in_malicious = phish_urls[phish_urls.isin(malicious_urls)]\n",
    "\n",
    "print(phish_urls_in_malicious.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "benign_url = pd.read_csv(\"datasets/benign_urls.csv\")\n",
    "\n",
    "benign_urls_in_malicious = benign_url[benign_url.isin(malicious_urls)]\n",
    "\n",
    "print(benign_urls_in_malicious.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Justin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- at_count\n",
      "- non_alphanumeric_count\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- pd_at_count\n",
      "- pd_hyphen_count\n",
      "- pd_in_alex_top_1m\n",
      "- pd_non_alphanumeric_count\n",
      "- pd_num_count\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 27 features, but RandomForestClassifier is expecting 30 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m phish_set \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mphish_set_X2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m phish_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_rfc1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphish_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(phish_pred))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mcount_nonzero(phish_pred \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(phish_pred))\n",
      "File \u001b[1;32mc:\\Users\\Justin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:808\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    788\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 808\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Justin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:850\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    848\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    853\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\Justin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:579\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 579\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Justin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Justin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 27 features, but RandomForestClassifier is expecting 30 features as input."
     ]
    }
   ],
   "source": [
    "phish_set = pd.read_csv(\"datasets\\phish_set_X2.csv\")\n",
    "phish_pred = model_rfc1.predict(phish_set)\n",
    "print(len(phish_pred))\n",
    "print(np.count_nonzero(phish_pred == 0)/len(phish_pred))\n",
    "print(np.count_nonzero(phish_pred == 1)/len(phish_pred))\n",
    "print(np.count_nonzero(phish_pred == 2)/len(phish_pred))\n",
    "print(np.count_nonzero(phish_pred == 3)/len(phish_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345738\n",
      "0.04075051050217216\n",
      "0.29994388814651557\n",
      "0.6527052276579375\n",
      "0.006600373693374752\n"
     ]
    }
   ],
   "source": [
    "benign_set = pd.read_csv(\"datasets/benign_dataset_X2.csv\")\n",
    "benign_pred = model_rfc1.predict(benign_set)\n",
    "print(len(benign_pred))\n",
    "count = np.count_nonzero(benign_pred == 0)\n",
    "print(np.count_nonzero(benign_pred == 0)/len(benign_pred))\n",
    "print(np.count_nonzero(benign_pred == 1)/len(benign_pred))\n",
    "print(np.count_nonzero(benign_pred == 2)/len(benign_pred))\n",
    "print(np.count_nonzero(benign_pred == 3)/len(benign_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7091\n"
     ]
    }
   ],
   "source": [
    "malicious_phish = pd.read_csv(\"datasets/malicious_phish.csv\")\n",
    "# Filter the DataFrame based on the conditions\n",
    "filtered_rows = malicious_phish[(malicious_phish['url'].str.contains(\"https://\")) & (malicious_phish['type'] == \"phishing\")]\n",
    "\n",
    "# Print the filtered rows\n",
    "print(len(filtered_rows))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
