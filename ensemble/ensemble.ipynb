{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined models\n",
    "1) rf-benign-specialize\n",
    "2) rf-general\n",
    "3) rf-lexical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_FNR_accuracy(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    for label_class in range(4):\n",
    "        FN = sum(conf_matrix[label_class][i] for i in range(len(conf_matrix)) if i != label_class)  \n",
    "        \n",
    "        TP = conf_matrix[label_class][label_class]  \n",
    "        \n",
    "        TN = np.sum(np.delete(np.delete(conf_matrix, label_class, axis=0), label_class, axis=1))\n",
    "        \n",
    "        accuracy = (TP + TN) / np.sum(conf_matrix)\n",
    "        print(\"Accuracy for class\", label_class, \":\", accuracy)\n",
    "\n",
    "        FNR = FN / (FN + TP) if (FN + TP) > 0 else -1\n",
    "        print(\"FNR for class\", label_class, \":\", FNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rf-general.pkl', RandomForestClassifier(max_depth=20, n_estimators=50, random_state=69)), ('rf-lexical.pkl', RandomForestClassifier(max_depth=20, n_estimators=50, random_state=69)), ('rf-benign-specialize.pkl', RandomForestClassifier(max_depth=20, n_estimators=50, random_state=69))]\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model_files = [file for file in os.listdir(os.getcwd()) if file.endswith(\".pkl\")]\n",
    "models = []\n",
    "for file in model_files:\n",
    "    with open(file, \"rb\") as file:\n",
    "        models.append((file.name, pickle.load(file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for training ensemble model\n",
    "training_dataset = {'rf-benign-specialize.pkl': 'rf-benign-specialize-features.csv',\n",
    "                    'rf-general.pkl': 'rf-general-features.csv',\n",
    "                    'rf-lexical.pkl': 'rf-lexical-features.csv'}\n",
    "\n",
    "# X_train = pd.read_csv(\"../datasets/malicious_phish.csv\")\n",
    "y_train = pd.read_csv(\"../datasets/feature_updated_dataset_y.csv\")\n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf-general.pkl         www  url_length  digit_count  dot_count  bs_count  dash_count  \\\n",
      "0       0.0        30.0          8.0       30.0       3.0         0.0   \n",
      "1       0.0        16.0          0.0       16.0       0.0         1.0   \n",
      "2       0.0        35.0          1.0       35.0       2.0         0.0   \n",
      "3       0.0        31.0          1.0       31.0       3.0         0.0   \n",
      "4       1.0        88.0          7.0       88.0       3.0         1.0   \n",
      "...     ...         ...          ...        ...       ...         ...   \n",
      "651186  0.0        39.0         12.0       39.0       3.0         0.0   \n",
      "651187  0.0        44.0          7.0       44.0       4.0         2.0   \n",
      "651188  1.0        42.0          3.0       42.0       4.0         0.0   \n",
      "651189  0.0        45.0          0.0       45.0       2.0         0.0   \n",
      "651190  1.0        41.0          0.0       41.0       3.0         0.0   \n",
      "\n",
      "        url_entropy  params_count  subdomain_count  domain_extension  ...  \\\n",
      "0         -4.215061           0.0              1.0               0.0  ...   \n",
      "1         -3.375000           0.0              1.0               1.0  ...   \n",
      "2         -4.079143           0.0              1.0               0.0  ...   \n",
      "3         -3.708093           0.0              1.0               2.0  ...   \n",
      "4         -4.660343           3.0              1.0               3.0  ...   \n",
      "...             ...           ...              ...               ...  ...   \n",
      "651186    -4.355539           0.0              1.0               0.0  ...   \n",
      "651187    -4.243300           0.0              1.0               0.0  ...   \n",
      "651188    -4.147921           0.0              1.0               0.0  ...   \n",
      "651189    -4.102313           0.0              1.0               2.0  ...   \n",
      "651190    -4.143541           0.0              1.0               0.0  ...   \n",
      "\n",
      "        equals_count  ampersands_count  digit_letter_ratio  pd_num_count  \\\n",
      "0                0.0               0.0            0.444444           0.0   \n",
      "1                0.0               0.0            0.000000           0.0   \n",
      "2                0.0               0.0            0.034483           1.0   \n",
      "3                0.0               0.0            0.040000           0.0   \n",
      "4                4.0               3.0            0.111111           0.0   \n",
      "...              ...               ...                 ...           ...   \n",
      "651186           0.0               0.0            0.571429           0.0   \n",
      "651187           0.0               0.0            0.241379           0.0   \n",
      "651188           0.0               0.0            0.090909           0.0   \n",
      "651189           0.0               0.0            0.000000           0.0   \n",
      "651190           0.0               0.0            0.000000           0.0   \n",
      "\n",
      "        pd_non_alphanumeric_count  uppercase_dirs  path_count_special_chars  \\\n",
      "0                             1.0             0.0                       1.0   \n",
      "1                             3.0             0.0                       3.0   \n",
      "2                             1.0             0.0                       3.0   \n",
      "3                             1.0             0.0                       2.0   \n",
      "4                             2.0             0.0                       1.0   \n",
      "...                           ...             ...                       ...   \n",
      "651186                        1.0             0.0                       3.0   \n",
      "651187                        1.0             1.0                       4.0   \n",
      "651188                        1.0             0.0                       2.0   \n",
      "651189                        1.0             1.0                       7.0   \n",
      "651190                        1.0             0.0                       2.0   \n",
      "\n",
      "        path_uppercase_to_lowercase_ratio  params_length  queries_count  \n",
      "0                                0.000000            0.0            0.0  \n",
      "1                                0.000000            0.0            0.0  \n",
      "2                                0.000000            0.0            0.0  \n",
      "3                                0.000000            0.0            0.0  \n",
      "4                                0.000000           49.0            4.0  \n",
      "...                                   ...            ...            ...  \n",
      "651186                           0.000000            0.0            0.0  \n",
      "651187                           0.074074            0.0            0.0  \n",
      "651188                           0.000000            0.0            0.0  \n",
      "651189                           0.058824            0.0            0.0  \n",
      "651190                           0.000000            0.0            0.0  \n",
      "\n",
      "[651191 rows x 22 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asonata/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf-lexical.pkl         url  url.1     url.2  url.3  url.4  url.5  url.6  url.7  url.8  url.9  \\\n",
      "0        30      0  0.444444      0     11      0      1      0      0      0   \n",
      "1        16      0  0.000000      0     16      0      3      1      0      0   \n",
      "2        35      1  0.034483      0     11      1      1      0      0      0   \n",
      "3        31      0  0.040000      0     14      0      1      0      0      0   \n",
      "4        88     10  0.111111      0     17      0      2      1      0      0   \n",
      "...     ...    ...       ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "651186   39      0  0.571429      0      7      0      1      0      0      0   \n",
      "651187   44      0  0.241379      0     12      0      1      0      0      0   \n",
      "651188   42      0  0.090909      0     12      0      1      0      0      0   \n",
      "651189   45      3  0.000000      0     13      0      1      0      0      0   \n",
      "651190   41      0  0.000000      0     13      0      1      0      0      0   \n",
      "\n",
      "        ...  url.11  url.12  url.13  url.14  url.15  url.16  url.17    url.18  \\\n",
      "0       ...       0       3       0       0       0       0       2  0.000000   \n",
      "1       ...       0       0       0       0       0       0       0  0.000000   \n",
      "2       ...       0       2       0       0       0       2       0  0.000000   \n",
      "3       ...       0       3       0       0       0       1       0  0.000000   \n",
      "4       ...       0       1       0       0       0       1       0  0.000000   \n",
      "...     ...     ...     ...     ...     ...     ...     ...     ...       ...   \n",
      "651186  ...       0       3       0       0       0       1       3  0.000000   \n",
      "651187  ...       0       4       0       1       0       2       2  0.181818   \n",
      "651188  ...       0       4       0       0       0       0       1  0.000000   \n",
      "651189  ...       0       2       0       1       0       5       0  0.100000   \n",
      "651190  ...       0       3       0       0       0       0       0  0.000000   \n",
      "\n",
      "        url.19  url.20  \n",
      "0            0       0  \n",
      "1            0       0  \n",
      "2            0       0  \n",
      "3            0       0  \n",
      "4           22       4  \n",
      "...        ...     ...  \n",
      "651186       0       0  \n",
      "651187       0       0  \n",
      "651188       0       0  \n",
      "651189       0       0  \n",
      "651190       0       0  \n",
      "\n",
      "[651191 rows x 21 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- url.1\n- url.10\n- url.11\n- url.12\n- url.13\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m training_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(training_dataset[model_name])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_name, training_data)\n\u001b[0;32m----> 6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# prediction for model\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:905\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    885\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:947\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    945\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    946\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    950\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/cs3264/lib/python3.12/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- url.1\n- url.10\n- url.11\n- url.12\n- url.13\n- ...\n"
     ]
    }
   ],
   "source": [
    "# Prepare predictions from models\n",
    "for i in range(len(models)):\n",
    "    model_name, model = models[i]\n",
    "    training_data = pd.read_csv(training_dataset[model_name])\n",
    "    print(model_name, training_data)\n",
    "    y_pred = model.predict(training_data) # prediction for model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attached to endpoint prediction of above models\n",
    "ensemble_model = MLPClassifier(hidden_layer_sizes=(3, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on 0.2 validation split initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on phishing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on benign dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs3264",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
